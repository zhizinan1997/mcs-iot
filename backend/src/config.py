"""
MCS-IOT é…ç½®ç®¡ç†æ¨¡å— (Configuration Management)

è¯¥æ–‡ä»¶è´Ÿè´£ç³»ç»Ÿå„é¡¹é…ç½®çš„è¯»å–ã€ä¿®æ”¹ã€éªŒè¯åŠå…¶å¯¹åº”çš„ API æŽ¥å£ã€‚
ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š
1. å®šä¹‰ Pydantic æ¨¡åž‹ï¼Œç”¨äºŽéªŒè¯ Emailã€Webhookã€SMSã€æŠ¥è­¦ã€å¤§å±ã€å½’æ¡£ã€AI ç­‰æ¨¡å—çš„é…ç½®æ•°æ®ã€‚
2. æä¾› RESTful API æŽ¥å£ï¼Œå®žçŽ°é…ç½®çš„æŒä¹…åŒ–å­˜å‚¨ï¼ˆä¸»è¦å­˜å‚¨åœ¨ Redis ä¸­ï¼‰ã€‚
3. æ”¯æŒå¤šäº‘å­˜å‚¨æ–¹æ¡ˆï¼ˆCloudflare R2, è…¾è®¯äº‘ COS, é˜¿é‡Œäº‘ OSSï¼‰çš„å½’æ¡£é…ç½®ï¼Œå¹¶æä¾›è¿žæŽ¥æµ‹è¯•ã€‚
4. æä¾›æ‰‹åŠ¨è§¦å‘çš„æ•°æ®å¤‡ä»½ä¸Žæœ¬åœ°æ•°æ®åº“æ¸…ç†åŠŸèƒ½ã€‚
5. é›†æˆ AI æŽ¥å£é…ç½®åŠè¿žé€šæ€§æµ‹è¯•ã€‚

ç»“æž„ï¼š
- BaseModel ç±»ç¾¤: å„ç§é…ç½®é¡¹çš„æ•°æ®ç»“æž„å®šä¹‰ã€‚
- API è·¯ç”±: æŒ‰ç…§åŠŸèƒ½åˆ’åˆ†çš„é…ç½®ç®¡ç†æŽ¥å£ã€‚
- è¾…åŠ©å‡½æ•°: åŒ…æ‹¬é…ç½®è¿ç§»ã€å­˜å‚¨ç»ˆç»“ç‚¹æž„å»ºã€äº‘å­˜å‚¨è¿žæŽ¥æµ‹è¯•ç­‰é€»è¾‘ã€‚
"""
from fastapi import APIRouter, Depends, HTTPException, UploadFile, File
from pydantic import BaseModel
from typing import Optional, List
import json
import os

router = APIRouter()

class EmailConfig(BaseModel):
    enabled: bool = False
    smtp_host: str = ""
    smtp_port: int = 465
    sender: str = ""
    password: str = ""
    receivers: List[str] = []

class WebhookConfig(BaseModel):
    enabled: bool = False
    url: str = ""
    platform: str = "custom"  # dingtalk, feishu, wecom, custom
    secret: str = ""  # åŠ ç­¾å¯†é’¥

class SMSConfig(BaseModel):
    enabled: bool = False
    access_key: str = ""
    secret_key: str = ""
    sign_name: str = ""
    template_id: str = ""

class AlarmGeneralConfig(BaseModel):
    """æŠ¥è­¦é€šç”¨é…ç½®ï¼šæ¶ˆæŠ–æ—¶é—´å’ŒæŠ¥è­¦æ—¶æ®µ"""
    debounce_minutes: int = 10  # æ¶ˆæŠ–æ—¶é—´(åˆ†é’Ÿ)
    time_restriction_enabled: bool = False  # æ˜¯å¦å¯ç”¨æ—¶æ®µé™åˆ¶
    time_restriction_days: List[int] = [1, 2, 3, 4, 5]  # å‘¨ä¸€åˆ°å‘¨äº”
    time_restriction_start: str = "08:00"  # å¼€å§‹æ—¶é—´
    time_restriction_end: str = "18:00"  # ç»“æŸæ—¶é—´

class DashboardConfig(BaseModel):
    title: str = "MCS-IoT Dashboard"
    refresh_rate: int = 5
    background_image: Optional[str] = None

class ArchiveConfig(BaseModel):
    """æ•°æ®å½’æ¡£é…ç½® (æ”¯æŒå¤šäº‘å­˜å‚¨: Cloudflare R2, è…¾è®¯äº‘ COS, é˜¿é‡Œäº‘ OSS)"""
    enabled: bool = False
    local_retention_days: int = 3  # æœ¬åœ°æ•°æ®åº“ä¿ç•™å¤©æ•°
    cloud_retention_days: int = 30  # äº‘ç«¯å¤‡ä»½ä¿ç•™å¤©æ•°
    # äº‘å­˜å‚¨æä¾›å•†: cloudflare, tencent, alibaba
    provider: str = "cloudflare"
    # é€šç”¨å­—æ®µ
    bucket: str = ""
    access_key: str = ""
    secret_key: str = ""
    # Cloudflare R2 ä¸“ç”¨
    account_id: str = ""
    # è…¾è®¯äº‘/é˜¿é‡Œäº‘ ä¸“ç”¨
    region: str = ""
    # å…¼å®¹æ—§ç‰ˆå­—æ®µ (deprecated)
    r2_retention_days: int = 30
    r2_account_id: str = ""
    r2_bucket: str = ""
    r2_access_key: str = ""
    r2_secret_key: str = ""

class SiteConfig(BaseModel):
    """ç«™ç‚¹å“ç‰Œé…ç½®"""
    site_name: str = "MCS-IoT"
    logo_url: str = ""
    browser_title: str = "MCS-IoT Dashboard"

class ScreenBgConfig(BaseModel):
    """å¤§å±èƒŒæ™¯é…ç½®"""
    image_url: str = ""

class WeatherConfig(BaseModel):
    """å¤©æ°”é…ç½®"""
    city_pinyin: str = "beijing"
    province: str = "åŒ—äº¬"
    city: str = "åŒ—äº¬"
    api_key: str = ""
    enabled: bool = True

class ScreenLayoutConfig(BaseModel):
    """å¤§å±é¢æ¿å¸ƒå±€é…ç½®"""
    left: float = 75
    center: float = 0
    right: float = 25
    mainHeight: float = 70
    trendHeight: float = 30
    leftInner: float = 35
    centerInner: float = 65
    leftPanel1: float = 35
    leftPanel2: float = 34
    leftPanel3: float = 27

# AI æŽ¥å£é…ç½®
AI_API_URL = "https://newapi2.zhizinan.top/v1"  # å›ºå®š API åœ°å€

class AIConfig(BaseModel):
    """ä»…é…ç½® API Key å’Œæ¨¡åž‹ï¼ŒURL å·²é”å®š"""
    api_key: str = ""
    model: str = "gpt-3.5-turbo"
    interval_hours: int = 4  # AI æ€»ç»“é—´éš”ï¼ˆå°æ—¶ï¼‰ï¼Œä»¥0ç‚¹ä¸ºèµ·ç‚¹è®¡ç®—æ£€æŸ¥ç‚¹

async def get_redis():
    from .main import redis_pool
    return redis_pool

async def get_db():
    from .main import db_pool
    return db_pool

# AI Config
@router.get("/ai", response_model=AIConfig)
async def get_ai_config(redis = Depends(get_redis)):
    data = await redis.get("config:ai")
    if data:
        return AIConfig(**json.loads(data))
    return AIConfig()

@router.put("/ai")
async def update_ai_config(config: AIConfig, redis = Depends(get_redis)):
    await redis.set("config:ai", config.json())
    return {"message": "AI config updated"}

@router.post("/ai/test")
async def test_ai_config(config: AIConfig):
    """Test AI configuration by sending a simple request"""
    try:
        from .ai import call_openai
        # Use a very simple prompt to save tokens and time
        response = await call_openai(config.dict(), "Hello, please reply with 'OK' only.")
        return {"success": True, "message": response}
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@router.get("/ai/history")
async def get_ai_history(db = Depends(get_db), page: int = 1, size: int = 20):
    """èŽ·å– AI æ€»ç»“åŽ†å²è®°å½•åˆ—è¡¨"""
    try:
        offset = (page - 1) * size
        async with db.acquire() as conn:
            # èŽ·å–æ€»æ•°
            count_result = await conn.fetchrow("SELECT COUNT(*) as total FROM ai_summary_logs")
            total = count_result['total'] if count_result else 0
            
            # èŽ·å–åˆ†é¡µæ•°æ®
            rows = await conn.fetch("""
                SELECT id, time_range, content, alarm_count, instrument_count, created_at
                FROM ai_summary_logs
                ORDER BY created_at DESC
                LIMIT $1 OFFSET $2
            """, size, offset)
            
            history = []
            for row in rows:
                history.append({
                    "id": row['id'],
                    "time_range": row['time_range'],
                    "content": row['content'],
                    "alarm_count": row['alarm_count'],
                    "instrument_count": row['instrument_count'],
                    "created_at": row['created_at'].isoformat() if row['created_at'] else None
                })
            
            return {"total": total, "data": history, "page": page, "size": size}
    except Exception as e:
        # å¦‚æžœè¡¨ä¸å­˜åœ¨ï¼Œè¿”å›žç©ºæ•°æ®
        if "does not exist" in str(e):
            return {"total": 0, "data": [], "page": page, "size": size}
        raise HTTPException(status_code=500, detail=str(e))

@router.delete("/ai/history")
async def clear_ai_history(db = Depends(get_db), redis = Depends(get_redis)):
    """æ¸…ç©ºæ‰€æœ‰ AI æ€»ç»“åŽ†å²è®°å½•"""
    try:
        async with db.acquire() as conn:
            result = await conn.execute("DELETE FROM ai_summary_logs")
            # èŽ·å–åˆ é™¤çš„è¡Œæ•°
            deleted_count = int(result.split()[-1]) if result else 0
        
        # åŒæ—¶æ¸…é™¤ Redis ä¸­çš„ç¼“å­˜
        await redis.delete("ai:summary:content")
        await redis.delete("ai:summary:timestamp")
        await redis.delete("ai:summary:range")
        
        return {"message": f"å·²æ¸…ç©º {deleted_count} æ¡ AI æ€»ç»“è®°å½•", "deleted_count": deleted_count}
    except Exception as e:
        if "does not exist" in str(e):
            return {"message": "AI æ€»ç»“è®°å½•è¡¨ä¸å­˜åœ¨", "deleted_count": 0}
        raise HTTPException(status_code=500, detail=str(e))

# Email Config
@router.get("/alarm/email", response_model=EmailConfig)
async def get_email_config(redis = Depends(get_redis)):
    data = await redis.get("config:email")
    if data:
        return EmailConfig(**json.loads(data))
    return EmailConfig()

@router.put("/alarm/email")
async def update_email_config(config: EmailConfig, redis = Depends(get_redis)):
    await redis.set("config:email", config.json())
    return {"message": "Email config updated"}

# Webhook Config
@router.get("/alarm/webhook", response_model=WebhookConfig)
async def get_webhook_config(redis = Depends(get_redis)):
    data = await redis.get("config:webhook")
    if data:
        return WebhookConfig(**json.loads(data))
    return WebhookConfig()

@router.put("/alarm/webhook")
async def update_webhook_config(config: WebhookConfig, redis = Depends(get_redis)):
    await redis.set("config:webhook", config.json())
    return {"message": "Webhook config updated"}

# SMS Config
@router.get("/alarm/sms", response_model=SMSConfig)
async def get_sms_config(redis = Depends(get_redis)):
    data = await redis.get("config:sms")
    if data:
        return SMSConfig(**json.loads(data))
    return SMSConfig()

@router.put("/alarm/sms")
async def update_sms_config(config: SMSConfig, redis = Depends(get_redis)):
    await redis.set("config:sms", config.json())
    return {"message": "SMS config updated"}

# Alarm General Config (æ¶ˆæŠ–æ—¶é—´å’ŒæŠ¥è­¦æ—¶æ®µ)
@router.get("/alarm/general", response_model=AlarmGeneralConfig)
async def get_alarm_general_config(redis = Depends(get_redis)):
    data = await redis.get("config:alarm_general")
    if data:
        return AlarmGeneralConfig(**json.loads(data))
    return AlarmGeneralConfig()

@router.put("/alarm/general")
async def update_alarm_general_config(config: AlarmGeneralConfig, redis = Depends(get_redis)):
    await redis.set("config:alarm_general", config.json())
    
    # ç«‹å³æ›´æ–°æ‰€æœ‰çŽ°æœ‰æ¶ˆæŠ–é”®çš„ TTLï¼Œä½¿æ–°é…ç½®ç«‹å³ç”Ÿæ•ˆ
    new_ttl = config.debounce_minutes * 60  # è½¬æ¢ä¸ºç§’
    debounce_keys = await redis.keys("alarm:debounce:*")
    updated_count = 0
    for key in debounce_keys:
        # åªæ›´æ–°ä»ç„¶å­˜åœ¨çš„é”®ï¼ˆè®¾ç½®æ–°çš„ TTLï¼‰
        current_ttl = await redis.ttl(key)
        if current_ttl > 0:
            # å¦‚æžœæ–° TTL å°äºŽå½“å‰å‰©ä½™æ—¶é—´ï¼Œç«‹å³æ›´æ–°
            # å¦‚æžœæ–° TTL å¤§äºŽå½“å‰å‰©ä½™æ—¶é—´ï¼Œä¹Ÿæ›´æ–°ï¼ˆå»¶é•¿æ¶ˆæŠ–æ—¶é—´ï¼‰
            await redis.expire(key, new_ttl)
            updated_count += 1
    
    return {"message": f"æŠ¥è­¦é€šç”¨é…ç½®å·²ä¿å­˜ï¼Œ{updated_count} ä¸ªè®¾å¤‡çš„æ¶ˆæŠ–æ—¶é—´å·²åŒæ­¥æ›´æ–°"}

# Dashboard Config
@router.get("/dashboard", response_model=DashboardConfig)
async def get_dashboard_config(redis = Depends(get_redis)):
    data = await redis.get("config:dashboard")
    if data:
        return DashboardConfig(**json.loads(data))
    return DashboardConfig()

@router.put("/dashboard")
async def update_dashboard_config(config: DashboardConfig, redis = Depends(get_redis)):
    await redis.set("config:dashboard", config.json())
    return {"message": "Dashboard config updated"}

# Screen Layout Config
@router.get("/screen-layout", response_model=ScreenLayoutConfig)
async def get_screen_layout_config(redis = Depends(get_redis)):
    data = await redis.get("config:screen_layout")
    if data:
        return ScreenLayoutConfig(**json.loads(data))
    return ScreenLayoutConfig()

@router.put("/screen-layout")
async def update_screen_layout_config(config: ScreenLayoutConfig, redis = Depends(get_redis)):
    await redis.set("config:screen_layout", config.json())
    return {"message": "Screen layout config updated"}


@router.post("/dashboard/background")
async def upload_background(file: UploadFile = File(...)):
    # Save to static folder
    upload_dir = "/app/static/uploads"
    os.makedirs(upload_dir, exist_ok=True)
    
    file_path = os.path.join(upload_dir, "background.png")
    with open(file_path, "wb") as f:
        content = await file.read()
        f.write(content)
    
    return {"message": "Background uploaded", "path": "/static/uploads/background.png"}

# Archive Config (Multi-Cloud: Cloudflare R2, Tencent COS, Alibaba OSS)
def _migrate_archive_config(config_dict: dict) -> dict:
    """
    è¿ç§»æ—§ç‰ˆé…ç½®åˆ°æ–°ç‰ˆç»Ÿä¸€æ ¼å¼
    æ—§æ ¼å¼ä½¿ç”¨ r2_* å‰ç¼€ï¼Œæ–°æ ¼å¼ä½¿ç”¨ç»Ÿä¸€å­—æ®µå
    """
    # è¿ç§»æ—§ç‰ˆ r2_endpoint åˆ° account_id
    if config_dict.get("r2_endpoint") and not config_dict.get("r2_account_id"):
        endpoint = config_dict.get("r2_endpoint", "")
        import re
        match = re.search(r'https?://([a-zA-Z0-9]+)\.r2\.cloudflarestorage\.com', endpoint)
        if match:
            config_dict["r2_account_id"] = match.group(1)
        config_dict.pop("r2_endpoint", None)
    
    # è¿ç§» r2_* å­—æ®µåˆ°æ–°ç‰ˆç»Ÿä¸€å­—æ®µ
    if config_dict.get("r2_account_id") and not config_dict.get("account_id"):
        config_dict["provider"] = "cloudflare"
        config_dict["account_id"] = config_dict.get("r2_account_id", "")
        config_dict["bucket"] = config_dict.get("r2_bucket", "")
        config_dict["access_key"] = config_dict.get("r2_access_key", "")
        config_dict["secret_key"] = config_dict.get("r2_secret_key", "")
        config_dict["cloud_retention_days"] = config_dict.get("r2_retention_days", 30)
    
    return config_dict

def _build_storage_endpoint(config: dict) -> tuple:
    """
    æ ¹æ®æä¾›å•†æž„å»ºå­˜å‚¨ endpoint URL
    è¿”å›ž: (endpoint_url, bucket_name, signature_version)
    """
    provider = config.get("provider", "cloudflare")
    bucket = config.get("bucket", "")
    
    if provider == "cloudflare":
        account_id = config.get("account_id", "").strip()
        endpoint = f"https://{account_id}.r2.cloudflarestorage.com"
        return (endpoint, bucket, "s3v4")
    
    elif provider == "tencent":
        region = config.get("region", "ap-guangzhou").strip()
        # è…¾è®¯äº‘ COS S3 å…¼å®¹ç«¯ç‚¹
        endpoint = f"https://cos.{region}.myqcloud.com"
        return (endpoint, bucket, "s3v4")
    
    elif provider == "alibaba":
        region = config.get("region", "oss-cn-hangzhou").strip()
        # é˜¿é‡Œäº‘ OSS S3 å…¼å®¹ç«¯ç‚¹
        endpoint = f"https://{region}.aliyuncs.com"
        return (endpoint, bucket, "s3v4")
    
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„å­˜å‚¨æä¾›å•†: {provider}")

@router.get("/archive", response_model=ArchiveConfig)
async def get_archive_config(redis = Depends(get_redis)):
    """èŽ·å–æ•°æ®å½’æ¡£é…ç½®ï¼ˆè‡ªåŠ¨è¿ç§»æ—§ç‰ˆé…ç½®ï¼‰"""
    data = await redis.get("config:archive")
    if data:
        config_dict = json.loads(data)
        
        # æ£€æŸ¥å¹¶è¿ç§»æ—§æ ¼å¼
        if config_dict.get("r2_endpoint") and not config_dict.get("r2_account_id"):
            config_dict = _migrate_archive_config(config_dict)
            # ä¿å­˜è¿ç§»åŽçš„é…ç½®
            await redis.set("config:archive", json.dumps(config_dict))
        
        return ArchiveConfig(**config_dict)
    return ArchiveConfig()

@router.put("/archive")
async def update_archive_config(config: ArchiveConfig, redis = Depends(get_redis)):
    """æ›´æ–°æ•°æ®å½’æ¡£é…ç½®"""
    await redis.set("config:archive", config.json())
    return {"message": "å½’æ¡£é…ç½®å·²ä¿å­˜"}

@router.post("/archive/test")
async def test_archive_connection(redis = Depends(get_redis)):
    """æµ‹è¯•äº‘å­˜å‚¨è¿žæŽ¥ (æ”¯æŒ Cloudflare R2, è…¾è®¯äº‘ COS, é˜¿é‡Œäº‘ OSS)"""
    import logging
    import subprocess
    import asyncio
    
    logger = logging.getLogger(__name__)
    
    data = await redis.get("config:archive")
    if not data:
        raise HTTPException(status_code=400, detail="å½’æ¡£é…ç½®æœªè®¾ç½®")
    
    config = json.loads(data)
    
    # è¿ç§»æ—§é…ç½®
    if config.get("r2_endpoint") or (config.get("r2_account_id") and not config.get("account_id")):
        config = _migrate_archive_config(config)
        await redis.set("config:archive", json.dumps(config))
    
    provider = config.get("provider", "cloudflare")
    provider_names = {"cloudflare": "Cloudflare R2", "tencent": "è…¾è®¯äº‘ COS", "alibaba": "é˜¿é‡Œäº‘ OSS"}
    provider_name = provider_names.get(provider, provider)
    
    # éªŒè¯å¿…å¡«å­—æ®µ
    if not config.get("bucket"):
        raise HTTPException(status_code=400, detail="è¯·å¡«å†™ Bucket åç§°")
    
    if not config.get("access_key") or not config.get("secret_key"):
        raise HTTPException(status_code=400, detail="è¯·å¡«å†™è®¿é—®å¯†é’¥")
    
    if provider == "cloudflare" and not config.get("account_id"):
        raise HTTPException(status_code=400, detail="è¯·å¡«å†™ Cloudflare è´¦æˆ· ID")
    
    if provider in ["tencent", "alibaba"] and not config.get("region"):
        raise HTTPException(status_code=400, detail="è¯·é€‰æ‹©å­˜å‚¨åŒºåŸŸ")
    
    try:
        endpoint, bucket, sig_version = _build_storage_endpoint(config)
        access_key = config['access_key']
        secret_key = config['secret_key']
        
        def test_connection():
            import boto3
            from botocore.config import Config as BotoConfig
            import os
            
            os.environ['PYTHONWARNINGS'] = 'ignore:Unverified HTTPS request'
            
            s3 = boto3.client(
                's3',
                endpoint_url=endpoint,
                aws_access_key_id=access_key,
                aws_secret_access_key=secret_key,
                config=BotoConfig(
                    signature_version=sig_version,
                    connect_timeout=10,
                    read_timeout=15,
                    retries={'max_attempts': 3, 'mode': 'standard'}
                ),
                region_name='auto' if provider == 'cloudflare' else config.get('region', 'auto')
            )
            
            s3.head_bucket(Bucket=bucket)
            return True
        
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(None, test_connection)
        
        return {"message": f"{provider_name} è¿žæŽ¥æˆåŠŸï¼Bucket: {bucket}"}
        
    except Exception as e:
        error_str = str(e)
        logger.error(f"Storage test failed ({provider}): {e}")
        
        if '403' in error_str or 'Forbidden' in error_str or 'AccessDenied' in error_str:
            raise HTTPException(status_code=400, detail="è®¿é—®è¢«æ‹’ç»ï¼Œè¯·æ£€æŸ¥ Access Key å’Œ Secret Key")
        elif '404' in error_str or 'NoSuchBucket' in error_str:
            raise HTTPException(status_code=400, detail=f"Bucket '{config.get('bucket')}' ä¸å­˜åœ¨")
        elif 'SSL' in error_str or 'ssl' in error_str:
            raise HTTPException(status_code=400, detail=f"SSL è¿žæŽ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œé…ç½®: {error_str[:100]}")
        else:
            raise HTTPException(status_code=500, detail=f"è¿žæŽ¥æµ‹è¯•å¤±è´¥: {error_str[:200]}")

@router.get("/archive/stats")
async def get_storage_stats(redis = Depends(get_redis), db = Depends(get_db)):
    """èŽ·å–å­˜å‚¨ç©ºé—´ç»Ÿè®¡"""
    stats = {
        "local_db": {"size_bytes": 0, "size_human": "0 B", "row_count": 0},
        "r2": {"size_bytes": 0, "size_human": "0 B", "file_count": 0, "message": ""}
    }
    
    def format_size(size_bytes: int) -> str:
        if size_bytes < 1024:
            return f"{size_bytes} B"
        elif size_bytes < 1024 * 1024:
            return f"{size_bytes / 1024:.2f} KB"
        elif size_bytes < 1024 * 1024 * 1024:
            return f"{size_bytes / (1024 * 1024):.2f} MB"
        else:
            return f"{size_bytes / (1024 * 1024 * 1024):.2f} GB"
    
    # èŽ·å–æœ¬åœ°æ•°æ®åº“å¤§å°
    try:
        async with db.acquire() as conn:
            # Use pg_database_size for total database size (more accurate)
            size_result = await conn.fetchrow("""
                SELECT pg_database_size(current_database()) as size,
                       (SELECT COUNT(*) FROM sensor_data) as count
            """)
            if size_result:
                stats["local_db"]["size_bytes"] = size_result['size'] or 0
                stats["local_db"]["size_human"] = format_size(size_result['size'] or 0)
                stats["local_db"]["row_count"] = size_result['count'] or 0
    except Exception as e:
        stats["local_db"]["error"] = str(e)
    
    # èŽ·å–äº‘ç«¯å­˜å‚¨å¤§å°
    config_str = await redis.get("config:archive")
    if config_str:
        config = json.loads(config_str)
        # è¿ç§»æ—§é…ç½®
        if config.get("r2_account_id") and not config.get("account_id"):
            config = _migrate_archive_config(config)
        
        # æ£€æŸ¥æ˜¯å¦é…ç½®äº†äº‘å­˜å‚¨
        has_config = config.get("account_id") or config.get("region")
        if has_config and config.get("bucket") and config.get("access_key"):
            try:
                import asyncio
                import boto3
                from botocore.config import Config as BotoConfig
                
                def get_cloud_stats():
                    endpoint, bucket, sig_version = _build_storage_endpoint(config)
                    provider = config.get("provider", "cloudflare")
                    
                    s3 = boto3.client(
                        's3',
                        endpoint_url=endpoint,
                        aws_access_key_id=config['access_key'],
                        aws_secret_access_key=config['secret_key'],
                        config=BotoConfig(
                            signature_version=sig_version,
                            retries={'max_attempts': 3, 'mode': 'standard'}
                        ),
                        region_name='auto' if provider == 'cloudflare' else config.get('region', 'auto')
                    )
                    
                    total_size = 0
                    file_count = 0
                    
                    paginator = s3.get_paginator('list_objects_v2')
                    for page in paginator.paginate(Bucket=bucket, Prefix='archive/'):
                        for obj in page.get('Contents', []):
                            total_size += obj.get('Size', 0)
                            file_count += 1
                    
                    return total_size, file_count
                
                loop = asyncio.get_event_loop()
                total_size, file_count = await loop.run_in_executor(None, get_cloud_stats)
                
                stats["r2"]["size_bytes"] = total_size
                stats["r2"]["size_human"] = format_size(total_size)
                stats["r2"]["file_count"] = file_count
            except ImportError:
                stats["r2"]["message"] = "boto3 æœªå®‰è£…"
            except Exception as e:
                stats["r2"]["error"] = str(e)
        else:
            stats["r2"]["message"] = "äº‘å­˜å‚¨æœªé…ç½®"
    else:
        stats["r2"]["message"] = "å½’æ¡£é…ç½®æœªè®¾ç½®"
    
    return stats

@router.get("/archive/files")
async def list_archive_files(redis = Depends(get_redis)):
    """åˆ—å‡ºäº‘å­˜å‚¨ä¸­çš„æ‰€æœ‰å½’æ¡£æ–‡ä»¶"""
    import asyncio
    
    config_str = await redis.get("config:archive")
    if not config_str:
        return {"files": [], "message": "å½’æ¡£é…ç½®æœªè®¾ç½®"}
    
    config = json.loads(config_str)
    
    # è¿ç§»æ—§é…ç½®
    if config.get("r2_account_id") and not config.get("account_id"):
        config = _migrate_archive_config(config)
    
    # æ£€æŸ¥æ˜¯å¦é…ç½®äº†äº‘å­˜å‚¨
    has_config = config.get("account_id") or config.get("region")
    if not has_config or not config.get("bucket"):
        return {"files": [], "message": "äº‘å­˜å‚¨æœªé…ç½®"}
    
    try:
        import boto3
        from botocore.config import Config as BotoConfig
        
        def get_files_list():
            endpoint, bucket, sig_version = _build_storage_endpoint(config)
            provider = config.get("provider", "cloudflare")
            
            s3 = boto3.client(
                's3',
                endpoint_url=endpoint,
                aws_access_key_id=config['access_key'],
                aws_secret_access_key=config['secret_key'],
                config=BotoConfig(
                    signature_version=sig_version,
                    retries={'max_attempts': 3, 'mode': 'standard'}
                ),
                region_name='auto' if provider == 'cloudflare' else config.get('region', 'auto')
            )
            
            files = []
            paginator = s3.get_paginator('list_objects_v2')
            for page in paginator.paginate(Bucket=bucket, Prefix='archive/'):
                for obj in page.get('Contents', []):
                    key = obj.get('Key', '')
                    size = obj.get('Size', 0)
                    last_modified = obj.get('LastModified')
                    
                    # ç”Ÿæˆé¢„ç­¾åä¸‹è½½ URL (æœ‰æ•ˆæœŸ 1 å°æ—¶)
                    download_url = s3.generate_presigned_url(
                        'get_object',
                        Params={'Bucket': bucket, 'Key': key},
                        ExpiresIn=3600
                    )
                    
                    # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
                    if size < 1024:
                        size_human = f"{size} B"
                    elif size < 1024 * 1024:
                        size_human = f"{size / 1024:.2f} KB"
                    elif size < 1024 * 1024 * 1024:
                        size_human = f"{size / (1024 * 1024):.2f} MB"
                    else:
                        size_human = f"{size / (1024 * 1024 * 1024):.2f} GB"
                    
                    files.append({
                        "key": key,
                        "name": key.split('/')[-1],
                        "size": size,
                        "size_human": size_human,
                        "last_modified": last_modified.isoformat() if last_modified else None,
                        "download_url": download_url
                    })
            
            # æŒ‰æ—¶é—´å€’åºæŽ’åˆ—
            files.sort(key=lambda x: x.get('last_modified', ''), reverse=True)
            return files
        
        loop = asyncio.get_event_loop()
        files = await loop.run_in_executor(None, get_files_list)
        
        return {"files": files, "count": len(files)}
        
    except ImportError:
        return {"files": [], "message": "boto3 æœªå®‰è£…"}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

class DeleteFileRequest(BaseModel):
    key: str  # R2 æ–‡ä»¶è·¯å¾„ï¼Œå¦‚ "archive/2025/12/sensor_data_20251220.csv.gz"

@router.post("/archive/delete")
async def delete_archive_file(request: DeleteFileRequest, redis = Depends(get_redis)):
    """åˆ é™¤ R2 ä¸­çš„å•ä¸ªå½’æ¡£æ–‡ä»¶"""
    import asyncio
    
    config_str = await redis.get("config:archive")
    if not config_str:
        raise HTTPException(status_code=400, detail="å½’æ¡£é…ç½®æœªè®¾ç½®")
    
    config = json.loads(config_str)
    
    # è¿ç§»æ—§é…ç½®
    if config.get("r2_account_id") and not config.get("account_id"):
        config = _migrate_archive_config(config)
    
    # æ£€æŸ¥æ˜¯å¦é…ç½®äº†äº‘å­˜å‚¨
    has_config = config.get("account_id") or config.get("region")
    if not has_config or not config.get("bucket"):
        raise HTTPException(status_code=400, detail="äº‘å­˜å‚¨æœªé…ç½®")
    
    file_key = request.key
    if not file_key or not file_key.startswith("archive/"):
        raise HTTPException(status_code=400, detail="æ— æ•ˆçš„æ–‡ä»¶è·¯å¾„")
    
    try:
        import boto3
        from botocore.config import Config as BotoConfig
        
        def delete_file():
            endpoint, bucket, sig_version = _build_storage_endpoint(config)
            provider = config.get("provider", "cloudflare")
            
            s3 = boto3.client(
                's3',
                endpoint_url=endpoint,
                aws_access_key_id=config['access_key'],
                aws_secret_access_key=config['secret_key'],
                config=BotoConfig(
                    signature_version=sig_version,
                    retries={'max_attempts': 3, 'mode': 'standard'}
                ),
                region_name='auto' if provider == 'cloudflare' else config.get('region', 'auto')
            )
            
            # å…ˆæ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            try:
                s3.head_object(Bucket=bucket, Key=file_key)
            except:
                raise Exception(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_key}")
            
            # åˆ é™¤æ–‡ä»¶
            s3.delete_object(Bucket=bucket, Key=file_key)
            return True
        
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(None, delete_file)
        
        file_name = file_key.split('/')[-1]
        return {
            "status": "success",
            "message": f"å·²åˆ é™¤æ–‡ä»¶: {file_name}",
            "deleted_key": file_key
        }
        
    except ImportError:
        raise HTTPException(status_code=500, detail="boto3 æœªå®‰è£…")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"åˆ é™¤å¤±è´¥: {str(e)}")

@router.post("/archive/backup")
async def manual_backup(redis = Depends(get_redis), db = Depends(get_db)):
    """æ‰‹åŠ¨è§¦å‘å¤‡ä»½ä»Šæ—¥æ•°æ®åˆ°äº‘å­˜å‚¨"""
    import asyncio
    from datetime import datetime, date
    
    config_str = await redis.get("config:archive")
    if not config_str:
        raise HTTPException(status_code=400, detail="å½’æ¡£é…ç½®æœªè®¾ç½®")
    
    config = json.loads(config_str)
    
    # è¿ç§»æ—§é…ç½®
    if config.get("r2_endpoint") or (config.get("r2_account_id") and not config.get("account_id")):
        config = _migrate_archive_config(config)
        await redis.set("config:archive", json.dumps(config))
    
    # æ£€æŸ¥æ˜¯å¦é…ç½®äº†äº‘å­˜å‚¨
    has_config = config.get("account_id") or config.get("region")
    if not has_config or not config.get("bucket"):
        raise HTTPException(status_code=400, detail="è¯·å…ˆé…ç½®äº‘å­˜å‚¨")
    
    try:
        import boto3
        from botocore.config import Config as BotoConfig
        import gzip
        import csv
        import io
        
        # æž„å»º endpoint URL
        endpoint, bucket, sig_version = _build_storage_endpoint(config)
        provider = config.get("provider", "cloudflare")
        
        # èŽ·å–ä»Šæ—¥æ•°æ®
        today = date.today()
        
        async with db.acquire() as conn:
            rows = await conn.fetch("""
                SELECT time, sn, v_raw, ppm, temp, humi, bat, rssi, seq
                FROM sensor_data
                WHERE time::date = $1
                ORDER BY time
            """, today)
        
        if not rows:
            return {"status": "empty", "message": f"ä»Šæ—¥ ({today}) æš‚æ— æ•°æ®å¯å¤‡ä»½"}
        
        # ç”Ÿæˆ CSV
        csv_buffer = io.StringIO()
        writer = csv.writer(csv_buffer)
        writer.writerow(["time", "sn", "v_raw", "ppm", "temp", "humi", "bat", "rssi", "seq"])
        
        for row in rows:
            writer.writerow([
                row['time'].isoformat(),
                row['sn'],
                row['v_raw'],
                row['ppm'],
                row['temp'],
                row['humi'],
                row['bat'],
                row['rssi'],
                row['seq']
            ])
        
        # åŽ‹ç¼©
        csv_content = csv_buffer.getvalue().encode('utf-8')
        gzipped = gzip.compress(csv_content)
        
        # ä¸Šä¼ åˆ°äº‘å­˜å‚¨
        file_name = f"sensor_data_{today.strftime('%Y%m%d')}_manual.csv.gz"
        cloud_path = f"archive/{today.year}/{today.month:02d}/{file_name}"
        
        def upload_to_cloud():
            s3 = boto3.client(
                's3',
                endpoint_url=endpoint,
                aws_access_key_id=config['access_key'],
                aws_secret_access_key=config['secret_key'],
                config=BotoConfig(
                    signature_version=sig_version,
                    retries={'max_attempts': 3, 'mode': 'standard'}
                ),
                region_name='auto' if provider == 'cloudflare' else config.get('region', 'auto')
            )
            s3.put_object(
                Bucket=bucket,
                Key=cloud_path,
                Body=gzipped,
                ContentType='application/gzip'
            )
            return True
        
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(None, upload_to_cloud)
        
        # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°
        size = len(gzipped)
        if size < 1024:
            size_human = f"{size} B"
        elif size < 1024 * 1024:
            size_human = f"{size / 1024:.2f} KB"
        else:
            size_human = f"{size / (1024 * 1024):.2f} MB"
        
        provider_names = {"cloudflare": "R2", "tencent": "COS", "alibaba": "OSS"}
        provider_name = provider_names.get(provider, "äº‘å­˜å‚¨")
        
        return {
            "status": "success",
            "message": f"å¤‡ä»½åˆ° {provider_name} æˆåŠŸï¼{len(rows)} æ¡è®°å½•ï¼Œ{size_human}",
            "row_count": len(rows),
            "file_size": size,
            "file_path": cloud_path
        }
        
    except ImportError:
        raise HTTPException(status_code=500, detail="boto3 æœªå®‰è£…")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"å¤‡ä»½å¤±è´¥: {str(e)}")

class CleanupRequest(BaseModel):
    days: int  # ä¿ç•™æœ€è¿‘å¤šå°‘å¤©çš„æ•°æ®

@router.post("/archive/cleanup")
async def manual_cleanup(request: CleanupRequest, db = Depends(get_db)):
    """æ‰‹åŠ¨æ¸…ç†æœ¬åœ°æ•°æ®åº“ä¸­è¶…è¿‡æŒ‡å®šå¤©æ•°çš„æ•°æ®"""
    from datetime import datetime, timedelta
    
    days = request.days
    if days < 1:
        raise HTTPException(status_code=400, detail="ä¿ç•™å¤©æ•°å¿…é¡»å¤§äºŽ 0")
    
    # å…è®¸çš„æ¸…ç†é€‰é¡¹ï¼š3å¤©ã€7å¤©ã€30å¤©
    allowed_days = [1, 3, 7, 30]
    if days not in allowed_days:
        raise HTTPException(status_code=400, detail=f"ä¿ç•™å¤©æ•°å¿…é¡»æ˜¯ä»¥ä¸‹ä¹‹ä¸€: {allowed_days}")
    
    try:
        cutoff_date = (datetime.now() - timedelta(days=days)).date()
        
        async with db.acquire() as conn:
            # å…ˆç»Ÿè®¡è¦åˆ é™¤çš„è¡Œæ•°
            count = await conn.fetchval("""
                SELECT COUNT(*) FROM sensor_data
                WHERE time::date < $1
            """, cutoff_date)
            
            if count == 0:
                return {
                    "status": "empty",
                    "message": f"æ²¡æœ‰ {days} å¤©å‰çš„æ•°æ®éœ€è¦æ¸…ç†",
                    "deleted_rows": 0,
                    "cutoff_date": str(cutoff_date)
                }
            
            # åˆ é™¤æ—§æ•°æ®
            await conn.execute("""
                DELETE FROM sensor_data
                WHERE time::date < $1
            """, cutoff_date)
            
            return {
                "status": "success",
                "message": f"æˆåŠŸæ¸…ç† {count} æ¡ {days} å¤©å‰çš„æ•°æ®",
                "deleted_rows": count,
                "cutoff_date": str(cutoff_date)
            }
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ¸…ç†å¤±è´¥: {str(e)}")

# Test notification
@router.post("/alarm/test")
async def test_notification(channel: str, redis = Depends(get_redis)):
    """Send a test notification to verify configuration"""
    import aiohttp
    import time
    import hashlib
    import hmac
    import base64
    import urllib.parse
    
    if channel == "webhook":
        data = await redis.get("config:webhook")
        if not data:
            raise HTTPException(status_code=400, detail="Webhook not configured")
        
        config = json.loads(data)
        if not config.get("enabled") or not config.get("url"):
            raise HTTPException(status_code=400, detail="Webhook not enabled or URL not set")
        
        url = config["url"]
        secret = config.get("secret", "")
        platform = config.get("platform", "custom")
        
        # è‡ªåŠ¨æ£€æµ‹å¹³å° (å¦‚æžœæ˜¯ custom ä½† URL åŒ…å«ç‰¹å®šåŸŸå)
        if platform == "custom":
            if "dingtalk.com" in url or "oapi.dingtalk" in url:
                platform = "dingtalk"
            elif "feishu.cn" in url or "open.feishu" in url:
                platform = "feishu"
            elif "qyapi.weixin.qq.com" in url:
                platform = "wecom"
        
        # æž„å»ºæµ‹è¯•æ¶ˆæ¯ (åŒ…å«ä¸­æ–‡é€—å·ä½œä¸ºå¸¸ç”¨å…³é”®è¯)
        test_msg = f"ðŸ”” MCS-IoT æµ‹è¯•é€šçŸ¥ï¼Œè¿™æ˜¯ä¸€æ¡æµ‹è¯•æ¶ˆæ¯ï¼Œç”¨äºŽéªŒè¯ Webhook é…ç½®æ˜¯å¦æ­£ç¡®ã€‚\n\næ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}"
        
        # æ ¹æ®å¹³å°æž„å»ºä¸åŒçš„ payload
        if platform == "dingtalk":
            # é’‰é’‰ç­¾å
            if secret:
                timestamp = str(round(time.time() * 1000))
                sign_str = f"{timestamp}\n{secret}"
                sign = base64.b64encode(
                    hmac.new(secret.encode(), sign_str.encode(), hashlib.sha256).digest()
                ).decode()
                url = f"{url}&timestamp={timestamp}&sign={urllib.parse.quote_plus(sign)}"
            
            payload = {
                "msgtype": "text",
                "text": {"content": test_msg}
            }
        elif platform == "feishu":
            payload = {
                "msg_type": "text",
                "content": {"text": test_msg}
            }
        elif platform == "wecom":
            payload = {
                "msgtype": "text",
                "text": {"content": test_msg}
            }
        else:
            payload = {
                "type": "test",
                "message": test_msg,
                "timestamp": int(time.time())
            }
        
        # å‘é€è¯·æ±‚
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(url, json=payload, timeout=10) as resp:
                    result = await resp.text()
                    if resp.status == 200:
                        # æ£€æŸ¥é’‰é’‰/é£žä¹¦ç­‰è¿”å›žçš„ errcode
                        try:
                            result_json = json.loads(result)
                            errcode = result_json.get("errcode", result_json.get("code", 0))
                            errmsg = result_json.get("errmsg", result_json.get("msg", ""))
                            if errcode != 0:
                                raise HTTPException(status_code=400, detail=f"Webhook è¿”å›žé”™è¯¯: {errmsg}")
                        except json.JSONDecodeError:
                            pass  # éž JSON å“åº”ï¼Œå¿½ç•¥
                        return {"message": "Webhook æµ‹è¯•æ¶ˆæ¯å‘é€æˆåŠŸ", "response": result}
                    else:
                        raise HTTPException(status_code=resp.status, detail=f"Webhook è¿”å›žé”™è¯¯: {result}")
        except aiohttp.ClientError as e:
            raise HTTPException(status_code=500, detail=f"å‘é€å¤±è´¥: {str(e)}")
    
    elif channel == "email":
        data = await redis.get("config:email")
        if not data:
            raise HTTPException(status_code=400, detail="Email not configured")
        
        config = json.loads(data)
        if not config.get("enabled"):
            raise HTTPException(status_code=400, detail="Email not enabled")
        
        # ç®€åŒ–ç‰ˆé‚®ä»¶å‘é€æµ‹è¯•
        import smtplib
        from email.mime.text import MIMEText
        
        try:
            msg = MIMEText(f"MCS-IoT æµ‹è¯•é‚®ä»¶\n\nè¿™æ˜¯ä¸€æ¡æµ‹è¯•é‚®ä»¶ï¼Œç”¨äºŽéªŒè¯é‚®ä»¶é…ç½®æ˜¯å¦æ­£ç¡®ã€‚\n\næ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}")
            msg['Subject'] = 'ðŸ”” MCS-IoT æµ‹è¯•é€šçŸ¥'
            msg['From'] = config['sender']
            msg['To'] = ', '.join(config['receivers'])
            
            with smtplib.SMTP_SSL(config['smtp_host'], config['smtp_port']) as server:
                server.login(config['sender'], config['password'])
                server.sendmail(config['sender'], config['receivers'], msg.as_string())
            
            
            return {"message": "é‚®ä»¶æµ‹è¯•å‘é€æˆåŠŸ"}
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"å‘é€å¤±è´¥: {str(e)}")
    
    else:
        raise HTTPException(status_code=400, detail="Unknown channel")

# Site Config
@router.get("/site", response_model=SiteConfig)
async def get_site_config(redis = Depends(get_redis)):
    data = await redis.get("config:site")
    if data:
        return json.loads(data)
    return SiteConfig()

@router.put("/site")
async def update_site_config(config: SiteConfig, redis = Depends(get_redis)):
    await redis.set("config:site", json.dumps(config.dict()))
    return config

# Screen Background Config
@router.get("/screen_bg", response_model=ScreenBgConfig)
async def get_screen_bg_config(redis = Depends(get_redis)):
    data = await redis.get("config:screen_bg")
    if data:
        return json.loads(data)
    return ScreenBgConfig()

@router.put("/screen_bg")
async def update_screen_bg_config(config: ScreenBgConfig, redis = Depends(get_redis)):
    await redis.set("config:screen_bg", json.dumps(config.dict()))
    return config

# Weather Config
@router.get("/weather", response_model=WeatherConfig)
async def get_weather_config(redis = Depends(get_redis)):
    data = await redis.get("config:weather")
    if data:
        return json.loads(data)
    return WeatherConfig()

@router.put("/weather")
async def update_weather_config(config: WeatherConfig, redis = Depends(get_redis)):
    await redis.set("config:weather", json.dumps(config.dict()))
    return config

# =============================================================================
# License API
# =============================================================================

@router.get("/license")
async def get_license_status():
    """èŽ·å–æŽˆæƒçŠ¶æ€å’Œè®¾å¤‡ç¼–ç """
    try:
        from .license import get_license_manager
        mgr = get_license_manager()
        return await mgr.get_license_status()
    except Exception as e:
        # å¦‚æžœ license manager æœªåˆå§‹åŒ–ï¼Œè¿”å›žåŸºæœ¬ä¿¡æ¯
        from .license import LicenseManager
        import os
        import hashlib
        
        # Generate device ID using same logic as LicenseManager
        machine_id = None
        
        # Priority 1: Mounted host machine-id
        if os.path.exists("/app/host_machine_id"):
            with open("/app/host_machine_id", "r") as f:
                machine_id = f.read().strip()
        # Priority 2: System machine-id
        elif os.path.exists("/etc/machine-id"):
            with open("/etc/machine-id", "r") as f:
                machine_id = f.read().strip()
        # Priority 3: Fallback
        else:
            import socket
            import uuid
            hostname = socket.gethostname()
            mac = hex(uuid.getnode())[2:]
            machine_id = f"{hostname}:{mac}"
        
        hash_bytes = hashlib.sha256(machine_id.encode()).digest()
        hex_str = hash_bytes.hex()[:12].upper()
        device_id = f"MCS-{hex_str[:4]}-{hex_str[4:8]}-{hex_str[8:12]}"
        
        return {
            "device_id": device_id,
            "status": "unlicensed",
            "error": str(e),
            "contact": "zinanzhi@gmail.com",
            "features": []
        }

@router.post("/license/verify")
async def verify_license():
    """æ‰‹åŠ¨è§¦å‘æŽˆæƒéªŒè¯"""
    try:
        from .license import get_license_manager
        mgr = get_license_manager()
        return await mgr.verify_license()
    except Exception as e:
        return {"valid": False, "error": str(e)}
